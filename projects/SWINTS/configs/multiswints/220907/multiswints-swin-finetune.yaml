_BASE_: "../Base-multiswints_swin.yaml"
MODEL:
  WEIGHTS: "output/multiswints-pretrain/model_0159999.pth"
  SWINTS:
    NUM_PROPOSALS: 300
    NUM_CLASSES: 2
  LANGUAGE_HEAD:
    NUM_CLASSES: 8
    PREDICTOR: V1LanguagePredictor
    INPUT_H: 32
    INPUT_W: 32
    INPUT_C: 256
    CONV1_C: 64
    CONV2_C: 32
  REC_HEAD:
    PRETRAIN: False
DATASETS:
  TRAIN: ("MLT19_train", "MLT19_Synthetic",)
  TEST:  ("MLT19_test",)
  TASK: (1,3,4,)
SEQUENCE:
  MULTI: True
  BOS_TOKEN: 0
  BEAM_SEARCH: False
  ARABIC:
    EMBED_SIZE: 100
    HIDDEN_SIZE: 256
    NUM_CHAR: 80
  BENGALI:
    EMBED_SIZE: 100
    HIDDEN_SIZE: 256
    NUM_CHAR: 110
  CHINESE:
    EMBED_SIZE: 200
    HIDDEN_SIZE: 256
    NUM_CHAR: 5200
  DEVANAGARI:
    EMBED_SIZE: 100
    HIDDEN_SIZE: 256
    NUM_CHAR: 110
  HANGUL:
    EMBED_SIZE: 200
    HIDDEN_SIZE: 256
    NUM_CHAR: 1500
  JAPANESE:
    EMBED_SIZE: 200
    HIDDEN_SIZE: 256
    NUM_CHAR: 2242
  LATIN:
    EMBED_SIZE: 150
    HIDDEN_SIZE: 256
    NUM_CHAR: 250
  SYMBOL:
    EMBED_SIZE: 100
    HIDDEN_SIZE: 256
    NUM_CHAR: 60
  LANGUAGES:
  - ar
  - bn
  - hi
  - ja
  - ko
  - la
  - zh
  - symbol
  LANGUAGES_ENABLED:
  - ar
  - bn
  - hi
  - ja
  - ko
  - la
  - zh
  - symbol
  LANGUAGES_UNFREEZED:
  - ar
  - bn
  - hi
  - ja
  - ko
  - la
  - zh
  - symbol
  NUM_SEQ_HEADS: 8
  RESIZE_HEIGHT: 16
  RESIZE_WIDTH: 64
  LOSS_WEIGHT: 0.5
SOLVER:
  BASE_LR: 0.00001
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 2000
  IMS_PER_BATCH: 16
  STEPS: (40000,) # finetune can merge into pretrain and enlarge first milestone
  MAX_ITER: 60000
  CHECKPOINT_PERIOD: 5000
  DISPLAY_FREQ: 50
INPUT:
  FORMAT: "RGB"
  MIN_SIZE_TEST: 2000
  MAX_SIZE_TEST: 2824
TEST:
  RUN_ALL_HEADS: True
  EVAL_PERIOD: 5000
  DET_CONF_THRESH: 0.4
  LANG_CONF_THRESH: 0.1
  SEQ_CONF_THRESH: 0.4
  SAMPLE: -1  # set -1 to use full sets
OUTPUT_DIR: "./output/multiswints_finetune"